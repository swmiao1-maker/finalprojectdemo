<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Reactive Static Visualizer</title>
<style>
html, body {
    margin: 0;
    padding: 0;
    background: black;
    overflow: hidden;
    color: white;
    font-family: sans-serif;
}

canvas { display: block; }

#controls {
    position: fixed;
    bottom: 12px;
    left: 50%;
    transform: translateX(-50%);
    display: flex;
    gap: 10px;
    z-index: 10;
}

button, input {
    padding: 6px 12px;
    background: #111;
    color: white;
    border: 1px solid #444;
    cursor: pointer;
}
button:disabled {
    opacity: 0.4;
    cursor: default;
}
</style>
</head>
<body>

<canvas id="canvas"></canvas>

<div id="controls">
    <button id="micBtn">Enable Mic</button>
    <input type="file" id="audioInput" accept="audio/*" disabled />
    <button id="playBtn" disabled>Play</button>
    <button id="stopBtn" disabled>Stop</button>
</div>

<script>
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

function resize() {
    canvas.width = innerWidth;
    canvas.height = innerHeight;
}
window.addEventListener("resize", resize);
resize();

/* ================= Audio ================= */
let audioCtx, analyser, dataArray;
let micSource, audioEl, audioSource;
let musicGain;
let audioStartTime = null;

/* ================= Static Visual ================= */
let staticAmount = 0;
const STATIC_FADE_IN = 0.004;
const STATIC_FADE_OUT = 0.002;

/* ================= Controls ================= */
const micBtn = document.getElementById("micBtn");
const audioInput = document.getElementById("audioInput");
const playBtn = document.getElementById("playBtn");
const stopBtn = document.getElementById("stopBtn");

/* ================= Initialize Audio ================= */
function initAudio() {
    if (audioCtx) return;

    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 1024;
    dataArray = new Uint8Array(analyser.frequencyBinCount);

    musicGain = audioCtx.createGain();
    musicGain.gain.value = 1;
    musicGain.connect(analyser);
    analyser.connect(audioCtx.destination);
}

/* ================= Microphone ================= */
micBtn.onclick = async () => {
    try {
        initAudio();
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        micSource = audioCtx.createMediaStreamSource(stream);
        micSource.connect(musicGain);

        audioInput.disabled = false;
        micBtn.disabled = true;
    } catch {
        alert("Microphone permission denied");
    }
};

/* ================= Audio File ================= */
audioInput.onchange = async e => {
    const file = e.target.files[0];
    if (!file) return;

    if (audioEl) audioEl.pause();

    initAudio();
    await audioCtx.resume();

    audioEl = new Audio(URL.createObjectURL(file));
    audioEl.loop = true;

    audioSource = audioCtx.createMediaElementSource(audioEl);
    audioSource.connect(musicGain);

    playBtn.disabled = false;
    stopBtn.disabled = false;
};

/* ================= Play / Stop ================= */
playBtn.onclick = async () => {
    if (!audioEl) return;
    await audioCtx.resume();
    audioStartTime = performance.now();
    audioEl.play();
    playBtn.disabled = true;
};

stopBtn.onclick = () => {
    if (audioEl) audioEl.pause();
    if (audioEl) audioEl.currentTime = 0;
    if (musicGain) musicGain.gain.value = 1;
    audioStartTime = null;
    staticAmount = 0;
    playBtn.disabled = false;
};

/* ================= Visualizer ================= */
function drawCircle() {
    analyser.getByteFrequencyData(dataArray);

    const cx = canvas.width / 2;
    const cy = canvas.height / 2;
    const baseRadius = Math.min(cx, cy) * 0.78;

    ctx.save();
    ctx.translate(cx, cy);

    for (let i = 0; i < dataArray.length; i++) {
        const amp = dataArray[i];
        const len = amp * 0.12;
        const angle = (i / dataArray.length) * Math.PI * 2;

        ctx.rotate(angle);
        ctx.beginPath();
        ctx.moveTo(baseRadius, 0);
        ctx.lineTo(baseRadius + len, 0);
        ctx.strokeStyle = "white";
        ctx.lineWidth = 4;
        ctx.stroke();
        ctx.rotate(-angle);
    }

    ctx.restore();

    // Increase staticAmount based on audio amplitude
    const sum = dataArray.reduce((a,b)=>a+b,0)/dataArray.length;
    staticAmount += (sum/255) * STATIC_FADE_IN;
}

/* ================= Static Visual ================= */
function drawStatic() {
    const img = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const d = img.data;
    for (let i = 0; i < d.length; i += 4) {
        const v = Math.random() * 255;
        d[i] = d[i+1] = d[i+2] = v;
        d[i+3] = staticAmount * 120;
    }
    ctx.putImageData(img, 0, 0);
}

/* ================= Main Loop ================= */
function loop() {
    requestAnimationFrame(loop);

    ctx.fillStyle = "rgba(0,0,0,0.25)";
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    if (analyser) drawCircle();

    // Slowly fade out static if no audio
    if (!audioEl?.paused && audioStartTime) {
        staticAmount = Math.min(1, staticAmount);
    } else {
        staticAmount -= STATIC_FADE_OUT;
        staticAmount = Math.max(0, staticAmount);
    }

    // Fade out audio as static grows
    if (musicGain) musicGain.gain.value = 1 - staticAmount;

    if (staticAmount > 0) drawStatic();
}

loop();
</script>

</body>
</html>
