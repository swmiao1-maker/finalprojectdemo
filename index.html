<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Sound & Audio Wave Visualizer</title>
<style>
    body {
        margin: 0;
        overflow: hidden;
        background: #000;
        display: flex;
        justify-content: center;
        align-items: center;
        flex-direction: column;
        height: 100vh;
        color: #0f0;
        font-family: monospace;
    }
    canvas {
        width: 100vw;
        height: 70vh;
        background: #000;
        display: block;
    }
    button, input[type="file"] {
        margin: 10px;
        color: #0f0;
        font-size: 16px;
    }
</style>
</head>
<body>

<h3>Step 1: Allow microphone</h3>
<button id="startBtn">Allow Microphone & Initialize Audio</button>
<h3>Step 2: Upload an audio file</h3>
<input type="file" id="audioFile" accept="audio/*" disabled>

<canvas id="canvas"></canvas>

<script>
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
canvas.width = window.innerWidth;
canvas.height = window.innerHeight * 0.7;

let audioCtx, analyser, dataArray, source, audio;
let micStream;

// Step 1: Ask for microphone permission
document.getElementById('startBtn').addEventListener('click', async () => {
    try {
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        // Initialize AudioContext
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        if (audioCtx.state === 'suspended') await audioCtx.resume();

        // Connect microphone to analyser
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = 1024;
        dataArray = new Uint8Array(analyser.frequencyBinCount);

        const micSource = audioCtx.createMediaStreamSource(micStream);
        micSource.connect(analyser);

        draw(); // Start visualization for microphone
        alert("Microphone access granted! You can now upload audio.");
        document.getElementById('audioFile').disabled = false;
        document.getElementById('startBtn').disabled = true;
    } catch (err) {
        alert("Microphone permission denied!");
        console.error(err);
    }
});

// Step 2: Upload audio file
document.getElementById('audioFile').addEventListener('change', async (e) => {
    const file = e.target.files[0];
    if (!file) return;

    if (audio) {
        audio.pause();
        audio = null;
        if (source) source.disconnect();
    }

    audio = new Audio(URL.createObjectURL(file));
    audio.loop = true;

    if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    if (audioCtx.state === 'suspended') await audioCtx.resume();

    source = audioCtx.createMediaElementSource(audio);
    source.connect(analyser);
    analyser.connect(audioCtx.destination);

    await audio.play();
});

function draw() {
    requestAnimationFrame(draw);
    if (!analyser) return;

    analyser.getByteTimeDomainData(dataArray);

    ctx.fillStyle = "rgba(0,0,0,0.3)";
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    ctx.lineWidth = 3;
    ctx.strokeStyle = "#00ffcc";

    ctx.beginPath();
    const sliceWidth = canvas.width / dataArray.length;
    let x = 0;

    for (let i = 0; i < dataArray.length; i++) {
        const v = dataArray[i] / 128.0;
        const y = (v * canvas.height) / 2;
        if (i === 0) ctx.moveTo(x, y);
        else ctx.lineTo(x, y);
        x += sliceWidth;
    }

    ctx.stroke();
}
</script>
</body>
</html>
